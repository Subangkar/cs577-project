# -*- coding: utf-8 -*-
"""tester_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iIPL97tL_cQPN3e-TkGexzCgj8hfL2eU
"""

pip install datasets

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
    AutoModelForSequenceClassification,
    pipeline,
    MarianMTModel,
    MarianTokenizer
)
from datasets import load_dataset
import numpy as np
from tqdm import tqdm
from sklearn.metrics import roc_auc_score
import argparse
import random

# 1. Mount your Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Imports
import pandas as pd
from google.colab import files

import pickle

# --- CONFIG (match your training script) -------------------
DETECTOR_MODEL = "distilbert-base-uncased"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ----------------------------------------------------------------

def load_detector(checkpoint_path: str):
    tokenizer = AutoTokenizer.from_pretrained(DETECTOR_MODEL, use_fast=True)
    model = AutoModelForSequenceClassification.from_pretrained(
        DETECTOR_MODEL, num_labels=2
    ).to(DEVICE)
    state = torch.load(checkpoint_path, map_location=DEVICE)
    # handle both raw state_dict or dict containing 'model_state_dict'
    sd = state.get("model_state", state)
    model.load_state_dict(sd)
    model.eval()
    return tokenizer, model

from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report

def testing_pipeline(MODEL_TYPE, CHECKPOINT_PATH, TEST_PICKLE, BATCH_SIZE):
    # CHECKPOINT_PATH = "/content/drive/MyDrive/detector_vanilla_10000.pth"
    tokenizer, model = load_detector(CHECKPOINT_PATH)

    # TEST_PICKLE     = "/content/drive/MyDrive/linkedin_test.pkl"
    # BATCH_SIZE      = 2

    # 4️⃣ Load your test set
    #    If you pickled a DataFrame:
    df_test = pd.read_pickle(TEST_PICKLE)

    #    OR if you pickled a tuple/list of (texts, labels):
    # with open(TEST_PICKLE, 'rb') as f:
    #     texts, labels = pickle.load(f)

    # 5️⃣ Extract texts & labels (adjust column names as needed)
    texts  = df_test["Post Text"].tolist()
    labels = df_test["Label"].tolist()

    # 6️⃣ Tokenize & build a DataLoader
    encodings = tokenizer(
        texts,
        padding=True,
        truncation=True,
        return_tensors="pt"
    )
    dataset = TensorDataset(
        encodings["input_ids"],
        encodings["attention_mask"],
        torch.tensor(labels, dtype=torch.long),
    )
    loader = DataLoader(dataset, batch_size=BATCH_SIZE)

    # 7️⃣ Run the model to get logits, preds, and positive‑class_probs
    all_preds    = []
    all_probs    = []
    all_labels   = []

    with torch.no_grad():
        for input_ids, attention_mask, batch_labels in loader:
            input_ids     = input_ids.to(DEVICE)
            attention_mask= attention_mask.to(DEVICE)
            outputs       = model(input_ids=input_ids, attention_mask=attention_mask)
            logits        = outputs.logits           # shape (batch, 2)
            probs         = torch.softmax(logits, dim=1)[:,1]  # P(class=1)
            preds         = torch.argmax(logits, dim=1)

            all_probs .extend(probs.cpu().tolist())
            all_preds .extend(preds.cpu().tolist())
            all_labels.extend(batch_labels.tolist())

    # 8️⃣ Compute metrics
    acc   = accuracy_score(all_labels, all_preds)
    f1    = f1_score(all_labels, all_preds)
    auc   = roc_auc_score(all_labels, all_probs)

    print(f"Model:        {MODEL_TYPE}")
    print(f"Accuracy:     {acc:.4f}")
    print(f"F1 Score:     {f1:.4f}")
    print(f"ROC‑AUC:      {auc:.4f}")
    print("\nFull classification report:")
    print(classification_report(all_labels, all_preds, digits=4))

CHECKPOINT_PATHS = {"vanilla": "/content/drive/MyDrive/detector_vanilla_10000.pth", "lex": "/content/drive/MyDrive/detector_lex_10000.pth"}
TEST_PICKLE     = "/content/drive/MyDrive/linkedin_test.pkl"
BATCH_SIZE      = 2

for model_type, checkpoint_path in CHECKPOINT_PATHS.items():
    testing_pipeline(model_type, checkpoint_path, TEST_PICKLE, BATCH_SIZE)

